{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Control: Control theory problems from the classic RL literature\n",
    "\n",
    "<br><br>\n",
    "\n",
    "In this notebook we will present some classic environments in Reinforcement Learning research. These environments have continuous states spaces (i.e., infinite possible states) and therefore tabular methods cannot solve them. To tackle these environments (and more complex ones) we will have two tools:\n",
    "\n",
    "- Extend the tabular methods with the techniques of discretization and tile coding\n",
    "- Use function approximators (Neural Networks)\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "<div style=\"text-align:center\">\n",
    "    <b>This notebook belongs to the course \"Reinforcement Learning: beginner to master\".</b>\n",
    "    <br><br>\n",
    "    <a href=\"https://www.udemy.com\">Reinforcement Learning: beginner to master</a> (English)\n",
    "    <br>\n",
    "    <a href=\"https://www.udemy.com\">Reinforcement Learning: de principiante a maestro</a> (Spanish)\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr style=\"background-color: transparent\">\n",
    "    <td style=\"width: 45%\">\n",
    "        <a target=\"_parent\" href=\"https://www.evlabs.io\" style=\"float: center\">\n",
    "            <img src=\"img/evlabs-square.png\" width=\"75\"/>\n",
    "        </a> \n",
    "    </td>\n",
    "    <td valign=\"bottom\">\n",
    "        <a target=\"_parent\" href=\"https://www.youtube.com/channel/UCksRNSzWuMV5IfdrPlglqqw\">\n",
    "            <img src=\"img/YouTube.png\" width=\"35\"/>\n",
    "        </a> \n",
    "    </td>\n",
    "    <td>\n",
    "        <a target=\"_parent\" href=\"https://www.linkedin.com/company/evlabs\">\n",
    "            <img src=\"img/LinkedIn.png\" width=\"35\"/>\n",
    "        </a> \n",
    "    </td>\n",
    "    <td>\n",
    "        <a target=\"_parent\" href=\"https://twitter.com/evelabs\">\n",
    "            <img src=\"img/Twitter.png\" width=\"35\"/>\n",
    "        </a> \n",
    "    </td>\n",
    "    <td>\n",
    "        <a target=\"_parent\" href=\"https://github.com/escape-velocity-labs/\">\n",
    "            <img src=\"img/GitHub.png\" width=\"35\"/>\n",
    "        </a> \n",
    "    </td>\n",
    "\n",
    "  </tr>\n",
    "  <tr style=\"background-color: transparent\">\n",
    "    <th style=\"text-align: center; width: 70%\">Escape Velocity Labs</th>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<table>\n",
    "    <tr style=\"background-color: transparent\">\n",
    "            <td>\n",
    "        <a target=\"_parent\" href=\"https://colab.research.google.com/github/escape-velocity-labs/evrl/blob/main/notebooks/Classic_Control_Introduction.ipynb\" style=\"float: center\">\n",
    "            <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "        </a>  \n",
    "    </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: center\">Open this notebook in Google colab</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(env: gym.Env) -> None:\n",
    "    env.reset()\n",
    "    done = False\n",
    "    img = plt.imshow(env.render(mode='rgb_array')) \n",
    "    while not done:\n",
    "        _, _, done, _ = env.step(env.action_space.sample())\n",
    "        img.set_data(env.render(mode='rgb_array')) \n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole: Keep the tip of the pole straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "test_env(env)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The state\n",
    "\n",
    "The states of the cartpole task will be represented by a vector of four real numbers:\n",
    "\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Cart Position             -4.8                    4.8\n",
    "        1       Cart Velocity             -Inf                    Inf\n",
    "        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        3       Pole Angular Velocity     -Inf                    Inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The actions available\n",
    "\n",
    "We can perform two actions in this environment:\n",
    "\n",
    "        0     Push cart to the left.\n",
    "        1     Push cart to the right.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acrobot: Swing the bar up to a certain height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Acrobot-v1')\n",
    "test_env(env)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The state\n",
    "\n",
    "The states of the cartpole task will be represented by a vector of six real numbers. The first two are the cosine and sine of the first joint. The next two are the cosine and sine of the other joint. The last two are the angular velocities of each joint.\n",
    "    \n",
    "$\\cos(\\theta_1), \\sin(\\theta_1), \\cos(\\theta_2), \\sin(\\theta_2), \\dot\\theta_1, \\dot\\theta_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The actions available\n",
    "\n",
    "We can perform two actions in this environment:\n",
    "\n",
    "    0    Apply +1 torque on the joint between the links.\n",
    "    1    Apply -1 torque on the joint between the links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MountainCar: Reach the goal from the bottom of the valley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "test_env(env)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The state\n",
    "\n",
    "The observation space consists of the car position $\\in [-1.2, 0.6]$ and car velocity $\\in [-0.07, 0.07]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The actions available\n",
    "\n",
    "\n",
    "The actions available three:\n",
    "\n",
    "    0    Accelerate to the left.\n",
    "    1    Don't accelerate.\n",
    "    2    Accelerate to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendulum: swing it and keep it upright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "test_env(env)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The state\n",
    "\n",
    "The state is represented by a vector of three values representing $\\cos(\\theta), \\sin(\\theta)$ and speed ($\\theta$ is the angle of the pendulum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The actions available\n",
    "\n",
    "The action is a real number in the interval $[-2, 2]$ that represents the torque applied on the pendulum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[1] OpenAI gym: classic control environments](https://gym.openai.com/envs/#classic_control)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
