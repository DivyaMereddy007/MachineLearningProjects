{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+b2ahy3Tffo8Gwhhp5Huw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lrK3LkHcoz06"},"outputs":[],"source":["#https://www.apdaga.com/2020/05/improving-deep-neural-networks-hyperparameter-tuning-regularization-and-optimization-week-2-optimization-methods-v1b.html\n","#Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization (Week 2 - Optimization Methods v1b)"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io\n","import math\n","import sklearn\n","import sklearn.datasets\n","\n","from opt_utils_v1a import load_params_and_grads, initialize_parameters, forward_propagation, backward_propagation\n","from opt_utils_v1a import compute_cost, predict, predict_dec, plot_decision_boundary, load_dataset\n","from testCases import *\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"rLgsF3AGo48_","executionInfo":{"status":"error","timestamp":1687731571622,"user_tz":300,"elapsed":1805,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"87527db2-96b4-42d8-9837-d7a3989b97be"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-3e4a39fdabb3>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopt_utils_v1a\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_params_and_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopt_utils_v1a\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtestCases\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opt_utils_v1a'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# GRADED FUNCTION: update_parameters_with_gd\n","\n","def update_parameters_with_gd(parameters, grads, learning_rate):\n","    \"\"\"\n","    Update parameters using one step of gradient descent\n","\n","    Arguments:\n","    parameters -- python dictionary containing your parameters to be updated:\n","                    parameters['W' + str(l)] = Wl\n","                    parameters['b' + str(l)] = bl\n","    grads -- python dictionary containing your gradients to update each parameters:\n","                    grads['dW' + str(l)] = dWl\n","                    grads['db' + str(l)] = dbl\n","    learning_rate -- the learning rate, scalar.\n","\n","    Returns:\n","    parameters -- python dictionary containing your updated parameters\n","    \"\"\"\n","    L = len(parameters) // 2 # number of layers in the neural networks\n","\n","    # Update rule for each parameter\n","    for l in range(L):\n","        ### START CODE HERE ### (approx. 2 lines)\n","        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate * grads['dW' + str(l+1)])  ## None\n","        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate * grads['db' + str(l+1)])  ## None\n","        ### END CODE HERE ###\n","\n","    return parameters"],"metadata":{"id":"ZMAHo_PlpANV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parameters, grads, learning_rate = update_parameters_with_gd_test_case()\n","\n","print(parameters.keys())\n","print(grads.keys()); print()\n","\n","parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n","print(\"W1 =\\n\" + str(parameters[\"W1\"]))\n","print(\"b1 =\\n\" + str(parameters[\"b1\"]))\n","print(\"W2 =\\n\" + str(parameters[\"W2\"]))\n","print(\"b2 =\\n\" + str(parameters[\"b2\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"23nZxZWtpRA5","executionInfo":{"status":"error","timestamp":1687731655756,"user_tz":300,"elapsed":153,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"6584b05c-ef57-43e8-99a9-a37e71a15754"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-6ebd5adaf668>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters_with_gd_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'update_parameters_with_gd_test_case' is not defined"]}]},{"cell_type":"code","source":["#(Batch) Gradient Descent:\n","X = data_input\n","Y = labels\n","parameters = initialize_parameters(layers_dims)\n","for i in range(0, num_iterations):\n","    # Forward propagation\n","    a, caches = forward_propagation(X, parameters)\n","    # Compute cost.\n","    cost += compute_cost(a, Y)\n","    # Backward propagation.\n","    grads = backward_propagation(a, caches, parameters)\n","    # Update parameters.\n","    parameters = update_parameters(parameters, grads)\n","#Stochastic Gradient Descent:\n","X = data_input\n","Y = labels\n","parameters = initialize_parameters(layers_dims)\n","for i in range(0, num_iterations):\n","    for j in range(0, m):\n","        # Forward propagation\n","        a, caches = forward_propagation(X[:,j], parameters)\n","        # Compute cost\n","        cost += compute_cost(a, Y[:,j])\n","        # Backward propagation\n","        grads = backward_propagation(a, caches, parameters)\n","        # Update parameters.\n","        parameters = update_parameters(parameters, grads)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"esfQDgFTpVJ4","executionInfo":{"status":"error","timestamp":1687732458902,"user_tz":300,"elapsed":147,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"6e44f254-fc10-4681-e7d0-b5d97a9db09b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-d528fc78c722>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#(Batch) Gradient Descent:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data_input' is not defined"]}]},{"cell_type":"code","source":["#2 - Mini-Batch Gradient descent\n","# GRADED FUNCTION: random_mini_batches\n","\n","def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n","    \"\"\"\n","    Creates a list of random minibatches from (X, Y)\n","\n","    Arguments:\n","    X -- input data, of shape (input size, number of examples)\n","    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n","    mini_batch_size -- size of the mini-batches, integer\n","\n","    Returns:\n","    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n","    \"\"\"\n","\n","    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n","    m = X.shape[1]                  # number of training examples\n","    mini_batches = []\n","\n","    # Step 1: Shuffle (X, Y)\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = X[:, permutation]\n","    shuffled_Y = Y[:, permutation].reshape((1,m))\n","\n","    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n","    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(0, num_complete_minibatches):\n","        ### START CODE HERE ### (approx. 2 lines)\n","        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k+1) * mini_batch_size] ##None\n","        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k+1) * mini_batch_size] ##None\n","        ### END CODE HERE ###\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","\n","    # Handling the end case (last mini-batch < mini_batch_size)\n","    if m % mini_batch_size != 0:\n","        ### START CODE HERE ### (approx. 2 lines)\n","        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m] ##None\n","        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m] ##None\n","        ### END CODE HERE ###\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","\n","    return mini_batches"],"metadata":{"id":"C7MR2bQ2sZQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_assess, Y_assess, mini_batch_size = random_mini_batches_test_case()\n","mini_batches = random_mini_batches(X_assess, Y_assess, mini_batch_size)\n","\n","\n","print (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n","print (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n","print (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n","print (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n","print (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape))\n","print (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n","print (\"mini batch sanity check: \" + str(mini_batches[0][0][0][0:3]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"FtbRr1DGvFoX","executionInfo":{"status":"error","timestamp":1687733177507,"user_tz":300,"elapsed":170,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"89045efa-cdd3-4021-eaf7-0b8f8f0ca506"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-16d53f1ecb44>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_assess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_assess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_mini_batches_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmini_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_mini_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_assess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_assess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"shape of the 1st mini_batch_X: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'random_mini_batches_test_case' is not defined"]}]},{"cell_type":"code","source":["#3 - Momentum\n","# GRADED FUNCTION: initialize_velocity\n","\n","def initialize_velocity(parameters):\n","    \"\"\"\n","    Initializes the velocity as a python dictionary with:\n","                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\"\n","                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n","    Arguments:\n","    parameters -- python dictionary containing your parameters.\n","                    parameters['W' + str(l)] = Wl\n","                    parameters['b' + str(l)] = bl\n","\n","    Returns:\n","    v -- python dictionary containing the current velocity.\n","                    v['dW' + str(l)] = velocity of dWl\n","                    v['db' + str(l)] = velocity of dbl\n","    \"\"\"\n","\n","    L = len(parameters) // 2 # number of layers in the neural networks\n","    v = {}\n","\n","    # Initialize velocity\n","    for l in range(L):\n","        ### START CODE HERE ### (approx. 2 lines)\n","        ##### SOLUTION 1: WORKING #####\n","        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0], parameters[\"W\" + str(l+1)].shape[1])) ##None\n","        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0], parameters[\"b\" + str(l+1)].shape[1])) ##None\n","\n","        ##### SOLUTION 2: WORKING #####\n","        #v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l+1)])\n","        #v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l+1)])\n","        ### END CODE HERE ###\n","\n","    return v"],"metadata":{"id":"osRV3MZzvIql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parameters = initialize_velocity_test_case()\n","\n","v = initialize_velocity(parameters)\n","print(\"v[\\\"dW1\\\"] =\\n\" + str(v[\"dW1\"]))\n","print(\"v[\\\"db1\\\"] =\\n\" + str(v[\"db1\"]))\n","print(\"v[\\\"dW2\\\"] =\\n\" + str(v[\"dW2\"]))\n","print(\"v[\\\"db2\\\"] =\\n\" + str(v[\"db2\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"5lhooMjwvoNT","executionInfo":{"status":"error","timestamp":1687733315192,"user_tz":300,"elapsed":157,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"e39e396b-d78a-4702-bdb4-3c4658f07569"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-d54b9c946726>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_velocity_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_velocity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"v[\\\"dW1\\\"] =\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dW1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"v[\\\"db1\\\"] =\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'initialize_velocity_test_case' is not defined"]}]},{"cell_type":"code","source":["# GRADED FUNCTION: update_parameters_with_momentum\n","\n","def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n","    \"\"\"\n","    Update parameters using Momentum\n","\n","    Arguments:\n","    parameters -- python dictionary containing your parameters:\n","                    parameters['W' + str(l)] = Wl\n","                    parameters['b' + str(l)] = bl\n","    grads -- python dictionary containing your gradients for each parameters:\n","                    grads['dW' + str(l)] = dWl\n","                    grads['db' + str(l)] = dbl\n","    v -- python dictionary containing the current velocity:\n","                    v['dW' + str(l)] = ...\n","                    v['db' + str(l)] = ...\n","    beta -- the momentum hyperparameter, scalar\n","    learning_rate -- the learning rate, scalar\n","\n","    Returns:\n","    parameters -- python dictionary containing your updated parameters\n","    v -- python dictionary containing your updated velocities\n","    \"\"\"\n","\n","    L = len(parameters) // 2 # number of layers in the neural networks\n","\n","    # Momentum update for each parameter\n","    for l in range(L):\n","\n","        ### START CODE HERE ### (approx. 4 lines)\n","        # compute velocities\n","        v[\"dW\" + str(l+1)] = beta * v[\"dW\" + str(l+1)] + (1 - beta) * grads['dW' + str(l+1)] ##None\n","        v[\"db\" + str(l+1)] = beta * v[\"db\" + str(l+1)] + (1 - beta) * grads['db' + str(l+1)] ##None\n","        # update parameters\n","        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * v[\"dW\" + str(l+1)] ##None\n","        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * v[\"db\" + str(l+1)] ##None\n","        ### END CODE HERE ###\n","\n","    return parameters, v"],"metadata":{"id":"FXDUjTgMvqSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parameters, grads, v = update_parameters_with_momentum_test_case()\n","\n","parameters, v = update_parameters_with_momentum(parameters, grads, v, beta = 0.9, learning_rate = 0.01)\n","print(\"W1 = \\n\" + str(parameters[\"W1\"]))\n","print(\"b1 = \\n\" + str(parameters[\"b1\"]))\n","print(\"W2 = \\n\" + str(parameters[\"W2\"]))\n","print(\"b2 = \\n\" + str(parameters[\"b2\"]))\n","print(\"v[\\\"dW1\\\"] = \\n\" + str(v[\"dW1\"]))\n","print(\"v[\\\"db1\\\"] = \\n\" + str(v[\"db1\"]))\n","print(\"v[\\\"dW2\\\"] = \\n\" + str(v[\"dW2\"]))\n","print(\"v[\\\"db2\\\"] = v\" + str(v[\"db2\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"e7Ke1X3rvtW8","executionInfo":{"status":"error","timestamp":1687733338063,"user_tz":300,"elapsed":160,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"9b33d1b4-4808-4bf0-e812-95be2abf71f0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4f79d5853d2e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters_with_momentum_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters_with_momentum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W1 = \\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b1 = \\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'update_parameters_with_momentum_test_case' is not defined"]}]},{"cell_type":"code","source":["#4 - Adam\n","\n","def initialize_adam(parameters) :\n","    \"\"\"\n","    Initializes v and s as two python dictionaries with:\n","                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\"\n","                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n","\n","    Arguments:\n","    parameters -- python dictionary containing your parameters.\n","                    parameters[\"W\" + str(l)] = Wl\n","                    parameters[\"b\" + str(l)] = bl\n","\n","    Returns:\n","    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n","                    v[\"dW\" + str(l)] = ...\n","                    v[\"db\" + str(l)] = ...\n","    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n","                    s[\"dW\" + str(l)] = ...\n","                    s[\"db\" + str(l)] = ...\n","\n","    \"\"\"\n","\n","    L = len(parameters) // 2 # number of layers in the neural networks\n","    v = {}\n","    s = {}\n","\n","    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n","    for l in range(L):\n","    ### START CODE HERE ### (approx. 4 lines)\n","        v[\"dW\" + str(l+1)] = np.zeros_like(parameters[\"W\" + str(l+1)]) ##None\n","        v[\"db\" + str(l+1)] = np.zeros_like(parameters[\"b\" + str(l+1)]) ##None\n","        s[\"dW\" + str(l+1)] = np.zeros_like(parameters[\"W\" + str(l+1)]) ##None\n","        s[\"db\" + str(l+1)] = np.zeros_like(parameters[\"b\" + str(l+1)]) ##None\n","    ### END CODE HERE ###\n","\n","    return v, s\n","\n","\n","\n","\n","\n","\n","In [11]:\n","parameters = initialize_adam_test_case()\n","\n","v, s = initialize_adam(parameters)\n","print(\"v[\\\"dW1\\\"] = \\n\" + str(v[\"dW1\"]))\n","print(\"v[\\\"db1\\\"] = \\n\" + str(v[\"db1\"]))\n","print(\"v[\\\"dW2\\\"] = \\n\" + str(v[\"dW2\"]))\n","print(\"v[\\\"db2\\\"] = \\n\" + str(v[\"db2\"]))\n","print(\"s[\\\"dW1\\\"] = \\n\" + str(s[\"dW1\"]))\n","print(\"s[\\\"db1\\\"] = \\n\" + str(s[\"db1\"]))\n","print(\"s[\\\"dW2\\\"] = \\n\" + str(s[\"dW2\"]))\n","print(\"s[\\\"db2\\\"] = \\n\" + str(s[\"db2\"]))"],"metadata":{"id":"dnvTJ4iivv3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GRADED FUNCTION: update_parameters_with_adam\n","\n","def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n","                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n","    \"\"\"\n","    Update parameters using Adam\n","\n","    Arguments:\n","    parameters -- python dictionary containing your parameters:\n","                    parameters['W' + str(l)] = Wl\n","                    parameters['b' + str(l)] = bl\n","    grads -- python dictionary containing your gradients for each parameters:\n","                    grads['dW' + str(l)] = dWl\n","                    grads['db' + str(l)] = dbl\n","    v -- Adam variable, moving average of the first gradient, python dictionary\n","    s -- Adam variable, moving average of the squared gradient, python dictionary\n","    learning_rate -- the learning rate, scalar.\n","    beta1 -- Exponential decay hyperparameter for the first moment estimates\n","    beta2 -- Exponential decay hyperparameter for the second moment estimates\n","    epsilon -- hyperparameter preventing division by zero in Adam updates\n","\n","    Returns:\n","    parameters -- python dictionary containing your updated parameters\n","    v -- Adam variable, moving average of the first gradient, python dictionary\n","    s -- Adam variable, moving average of the squared gradient, python dictionary\n","    \"\"\"\n","\n","    L = len(parameters) // 2                 # number of layers in the neural networks\n","    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n","    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n","\n","    # Perform Adam update on all parameters\n","    for l in range(L):\n","        # Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n","        ### START CODE HERE ### (approx. 2 lines)\n","        v[\"dW\" + str(l+1)] = beta1 * v[\"dW\" + str(l+1)] + (1 - beta1) * grads[\"dW\" + str(l+1)] ##None\n","        v[\"db\" + str(l+1)] = beta1 * v[\"db\" + str(l+1)] + (1 - beta1) * grads[\"db\" + str(l+1)] ##None\n","        ### END CODE HERE ###\n","\n","        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n","        ### START CODE HERE ### (approx. 2 lines)\n","        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)] / (1 - np.power(beta1,t)) ##None\n","        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)] / (1 - np.power(beta1,t)) ##None\n","        ### END CODE HERE ###\n","\n","        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n","        ### START CODE HERE ### (approx. 2 lines)\n","        s[\"dW\" + str(l+1)] = beta2 * s[\"dW\" + str(l+1)] + (1 - beta2) * np.power(grads[\"dW\" + str(l+1)],2) ##None\n","        s[\"db\" + str(l+1)] = beta2 * s[\"db\" + str(l+1)] + (1 - beta2) * np.power(grads[\"db\" + str(l+1)],2) ##None\n","        ### END CODE HERE ###\n","\n","        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n","        ### START CODE HERE ### (approx. 2 lines)\n","        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)] / (1 - np.power(beta2,t)) ##None\n","        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)] / (1 - np.power(beta2,t)) ##None\n","        ### END CODE HERE ###\n","\n","        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n","        ### START CODE HERE ### (approx. 2 lines)\n","        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate *  v_corrected[\"dW\" + str(l+1)] / (np.sqrt(s_corrected[\"dW\" + str(l+1)]) + epsilon) ##None\n","        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate *  v_corrected[\"db\" + str(l+1)] / (np.sqrt(s_corrected[\"db\" + str(l+1)]) + epsilon) ##None\n","        ### END CODE HERE ###\n","\n","    return parameters, v, s\n","\n","\n","\n","\n","\n","parameters, grads, v, s = update_parameters_with_adam_test_case()\n","parameters, v, s  = update_parameters_with_adam(parameters, grads, v, s, t = 2)\n","\n","print(\"W1 = \\n\" + str(parameters[\"W1\"]))\n","print(\"b1 = \\n\" + str(parameters[\"b1\"]))\n","print(\"W2 = \\n\" + str(parameters[\"W2\"]))\n","print(\"b2 = \\n\" + str(parameters[\"b2\"]))\n","print(\"v[\\\"dW1\\\"] = \\n\" + str(v[\"dW1\"]))\n","print(\"v[\\\"db1\\\"] = \\n\" + str(v[\"db1\"]))\n","print(\"v[\\\"dW2\\\"] = \\n\" + str(v[\"dW2\"]))\n","print(\"v[\\\"db2\\\"] = \\n\" + str(v[\"db2\"]))\n","print(\"s[\\\"dW1\\\"] = \\n\" + str(s[\"dW1\"]))\n","print(\"s[\\\"db1\\\"] = \\n\" + str(s[\"db1\"]))\n","print(\"s[\\\"dW2\\\"] = \\n\" + str(s[\"dW2\"]))\n","print(\"s[\\\"db2\\\"] = \\n\" + str(s[\"db2\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"6AeWVwlyx_h9","executionInfo":{"status":"error","timestamp":1687733937956,"user_tz":300,"elapsed":7,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"603123cd-aaa2-4fec-f8de-6474e90bf461"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-578d20007469>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters_with_adam_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters_with_adam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'update_parameters_with_adam_test_case' is not defined"]}]},{"cell_type":"code","source":["#5 - Model with different optimization algorithms\n","\n","'''Lets use the following \"moons\" dataset to test the different optimization methods. (The dataset is named \"moons\" because the data from each of the two classes looks a bit like a crescent-shaped moon.'''\n","train_X, train_Y = load_dataset()\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"AvtBpuwMyCVl","executionInfo":{"status":"error","timestamp":1687734011449,"user_tz":300,"elapsed":124,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"d1eea2fc-f935-416e-ffc6-00bf83ddef8c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-8373205cbab8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m'''Lets use the following \"moons\" dataset to test the different optimization methods. (The dataset is named \"moons\" because the data from each of the two classes looks a bit like a crescent-shaped moon.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"]}]},{"cell_type":"code","source":["def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n","          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 10000, print_cost = True):\n","    \"\"\"\n","    3-layer neural network model which can be run in different optimizer modes.\n","\n","    Arguments:\n","    X -- input data, of shape (2, number of examples)\n","    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n","    layers_dims -- python list, containing the size of each layer\n","    learning_rate -- the learning rate, scalar.\n","    mini_batch_size -- the size of a mini batch\n","    beta -- Momentum hyperparameter\n","    beta1 -- Exponential decay hyperparameter for the past gradients estimates\n","    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates\n","    epsilon -- hyperparameter preventing division by zero in Adam updates\n","    num_epochs -- number of epochs\n","    print_cost -- True to print the cost every 1000 epochs\n","\n","    Returns:\n","    parameters -- python dictionary containing your updated parameters\n","    \"\"\"\n","\n","    L = len(layers_dims)             # number of layers in the neural networks\n","    costs = []                       # to keep track of the cost\n","    t = 0                            # initializing the counter required for Adam update\n","    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n","    m = X.shape[1]                   # number of training examples\n","\n","    # Initialize parameters\n","    parameters = initialize_parameters(layers_dims)\n","\n","    # Initialize the optimizer\n","    if optimizer == \"gd\":\n","        pass # no initialization required for gradient descent\n","    elif optimizer == \"momentum\":\n","        v = initialize_velocity(parameters)\n","    elif optimizer == \"adam\":\n","        v, s = initialize_adam(parameters)\n","\n","    # Optimization loop\n","    for i in range(num_epochs):\n","\n","        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n","        seed = seed + 1\n","        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n","        cost_total = 0\n","\n","        for minibatch in minibatches:\n","\n","            # Select a minibatch\n","            (minibatch_X, minibatch_Y) = minibatch\n","\n","            # Forward propagation\n","            a3, caches = forward_propagation(minibatch_X, parameters)\n","\n","            # Compute cost and add to the cost total\n","            cost_total += compute_cost(a3, minibatch_Y)\n","\n","            # Backward propagation\n","            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n","\n","            # Update parameters\n","            if optimizer == \"gd\":\n","                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n","            elif optimizer == \"momentum\":\n","                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n","            elif optimizer == \"adam\":\n","                t = t + 1 # Adam counter\n","                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,\n","                                                               t, learning_rate, beta1, beta2,  epsilon)\n","        cost_avg = cost_total / m\n","\n","        # Print the cost every 1000 epoch\n","        if print_cost and i % 1000 == 0:\n","            print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n","        if print_cost and i % 100 == 0:\n","            costs.append(cost_avg)\n","\n","    # plot the cost\n","    plt.plot(costs)\n","    plt.ylabel('cost')\n","    plt.xlabel('epochs (per 100)')\n","    plt.title(\"Learning rate = \" + str(learning_rate))\n","    plt.show()\n","\n","    return parameters"],"metadata":{"id":"ZxamnjVzyPOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#5.1 - Mini-batch Gradient descent\n","\n","# train 3-layer model\n","layers_dims = [train_X.shape[0], 5, 2, 1]\n","parameters = model(train_X, train_Y, layers_dims, optimizer = \"gd\")\n","\n","# Predict\n","predictions = predict(train_X, train_Y, parameters)\n","\n","# Plot decision boundary\n","plt.title(\"Model with Gradient Descent optimization\")\n","axes = plt.gca()\n","axes.set_xlim([-1.5,2.5])\n","axes.set_ylim([-1,1.5])\n","plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"5A6moDchyVBB","executionInfo":{"status":"error","timestamp":1687734030061,"user_tz":300,"elapsed":152,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"d82d795d-07e8-44c2-8783-13bfaed1ba7e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-e8e76ed6f6dd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train 3-layer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlayers_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"]}]},{"cell_type":"code","source":["#5.2 - Mini-batch gradient descent with momentum\n","\n","# train 3-layer model\n","layers_dims = [train_X.shape[0], 5, 2, 1]\n","parameters = model(train_X, train_Y, layers_dims, beta = 0.9, optimizer = \"momentum\")\n","\n","# Predict\n","predictions = predict(train_X, train_Y, parameters)\n","\n","# Plot decision boundary\n","plt.title(\"Model with Momentum optimization\")\n","axes = plt.gca()\n","axes.set_xlim([-1.5,2.5])\n","axes.set_ylim([-1,1.5])\n","plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"LyexfrzeyY0D","executionInfo":{"status":"error","timestamp":1687734057791,"user_tz":300,"elapsed":159,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"98d8f392-09d4-424d-bcb5-412cb4ec7fb9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-6cb5b9c49184>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train 3-layer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlayers_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"]}]},{"cell_type":"code","source":["#5.3 - Mini-batch with Adam mode\n","\n","# train 3-layer model\n","layers_dims = [train_X.shape[0], 5, 2, 1]\n","parameters = model(train_X, train_Y, layers_dims, optimizer = \"adam\")\n","\n","# Predict\n","predictions = predict(train_X, train_Y, parameters)\n","\n","# Plot decision boundary\n","plt.title(\"Model with Adam optimization\")\n","axes = plt.gca()\n","axes.set_xlim([-1.5,2.5])\n","axes.set_ylim([-1,1.5])\n","plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"],"metadata":{"id":"qpHTMeThyflR","executionInfo":{"status":"error","timestamp":1687734073316,"user_tz":300,"elapsed":147,"user":{"displayName":"Divya Mereddy","userId":"10248213292416480180"}},"outputId":"769f496e-a2f6-4ecf-8b14-43cc37b59988","colab":{"base_uri":"https://localhost:8080/","height":240}},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-f77d1bdbc270>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train 3-layer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlayers_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NzRI2XPIyjap"},"execution_count":null,"outputs":[]}]}