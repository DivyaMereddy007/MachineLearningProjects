{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4cj0kjP0z32MoQ9oPr+Ox"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0PdZXJCSmudP","executionInfo":{"status":"ok","timestamp":1677262283683,"user_tz":360,"elapsed":4,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}}},"outputs":[],"source":["#Classification Validation Models"]},{"cell_type":"code","source":["import os, sys\n","\n","import numpy as np\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import timeit\n","import pickle\n","import sys\n","from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n","                            precision_recall_curve, roc_curve, accuracy_score, fbeta_score\n","from sklearn.exceptions import NotFittedError"],"metadata":{"id":"wKY0nynqn1HY","executionInfo":{"status":"ok","timestamp":1677265622321,"user_tz":360,"elapsed":247,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Basic Function\n"],"metadata":{"id":"4G2nSSMurEqq","executionInfo":{"status":"ok","timestamp":1677265588994,"user_tz":360,"elapsed":2,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def confusion_plot(matrix, labels=None):\n","    \"\"\" Display binary confusion matrix as a Seaborn heatmap \"\"\"\n","    \n","    labels = labels if labels else ['Negative (0)', 'Positive (1)']\n","    \n","    fig, ax = plt.subplots(nrows=1, ncols=1)\n","    sns.heatmap(data=matrix, cmap='Blues', annot=True, fmt='d',\n","                xticklabels=labels, yticklabels=labels, ax=ax)\n","    ax.set_xlabel('PREDICTED')\n","    ax.set_ylabel('ACTUAL')\n","    ax.set_title('Confusion Matrix')\n","    plt.close()\n","    \n","    return fig\n","\n","\n","\n","def roc_plot(y_true, y_probs, label, compare=False, ax=None):\n","    \"\"\" Plot Receiver Operating Characteristic (ROC) curve \n","        Set `compare=True` to use this function to compare classifiers. \"\"\"\n","    \n","    fpr, tpr, thresh = roc_curve(y_true, y_probs,\n","                                 drop_intermediate=False)\n","    auc = round(roc_auc_score(y_true, y_probs), 2)\n","    \n","    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n","    label = ' '.join([label, f'({auc})']) if compare else None\n","    sns.lineplot(x=fpr, y=tpr, ax=axis, label=label)\n","    \n","    if compare:\n","        axis.legend(title='Classifier (AUC)', loc='lower right')\n","    else:\n","        axis.text(0.72, 0.05, f'AUC = { auc }', fontsize=12,\n","                  bbox=dict(facecolor='green', alpha=0.4, pad=5))\n","            \n","        # Plot No-Info classifier\n","        axis.fill_between(fpr, fpr, tpr, alpha=0.3, edgecolor='g',\n","                          linestyle='--', linewidth=2)\n","        \n","    axis.set_xlim(0, 1)\n","    axis.set_ylim(0, 1)\n","    axis.set_title('ROC Curve')\n","    axis.set_xlabel('False Positive Rate [FPR]\\n(1 - Specificity)')\n","    axis.set_ylabel('True Positive Rate [TPR]\\n(Sensitivity or Recall)')\n","    \n","    plt.close()\n","    \n","    return axis if ax else fig\n","\n","\n","\n","def precision_recall_plot(y_true, y_probs, label, compare=False, ax=None):\n","    \"\"\" Plot Precision-Recall curve.\n","        Set `compare=True` to use this function to compare classifiers. \"\"\"\n","    \n","    p, r, thresh = precision_recall_curve(y_true, y_probs)\n","    p, r, thresh = list(p), list(r), list(thresh)\n","    p.pop()\n","    r.pop()\n","    \n","    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n","    \n","    if compare:\n","        sns.lineplot(r, p, ax=axis, label=label)\n","        axis.set_xlabel('Recall')\n","        axis.set_ylabel('Precision')\n","        axis.legend(loc='lower left')\n","    else:\n","        sns.lineplot(thresh, p, label='Precision', ax=axis)\n","        axis.set_xlabel('Threshold')\n","        axis.set_ylabel('Precision')\n","        axis.legend(loc='lower left')\n","\n","        axis_twin = axis.twinx()\n","        sns.lineplot(thresh, r, color='limegreen', label='Recall', ax=axis_twin)\n","        axis_twin.set_ylabel('Recall')\n","        axis_twin.set_ylim(0, 1)\n","        axis_twin.legend(bbox_to_anchor=(0.24, 0.18))\n","    \n","    axis.set_xlim(0, 1)\n","    axis.set_ylim(0, 1)\n","    axis.set_title('Precision Vs Recall')\n","    \n","    plt.close()\n","    \n","    return axis if ax else fig\n","\n","\n","\n","def feature_importance_plot(importances, feature_labels, ax=None):\n","    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n","    sns.barplot(x=importances, y=feature_labels, ax=axis)\n","    axis.set_title('Feature Importance Measures')\n","    \n","    plt.close()\n","    \n","    return axis if ax else fig\n","\n","\n","def train_clf(clf, x_train, y_train, sample_weight=None, refit=False):\n","    train_time = 0\n","    \n","    try:\n","        if refit:\n","            raise NotFittedError\n","        y_pred_train = clf.predict(x_train)\n","    except NotFittedError:\n","        start = timeit.default_timer()\n","        \n","        if sample_weight is not None:\n","            clf.fit(x_train, y_train, sample_weight=sample_weight)\n","        else:\n","            clf.fit(x_train, y_train)\n","        \n","        end = timeit.default_timer()\n","        train_time = end - start\n","        \n","        y_pred_train = clf.predict(x_train)\n","    \n","    train_acc = accuracy_score(y_train, y_pred_train)\n","    return clf, y_pred_train, train_acc, train_time\n","\n","\n"],"metadata":{"id":"Qjb0PC-_of7w","executionInfo":{"status":"ok","timestamp":1677265589141,"user_tz":360,"elapsed":2,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics._plot.precision_recall_curve import plot_precision_recall_curve, PrecisionRecallDisplay\n","\n","#additional Methods\n","\n","\n","def model_memory_size(clf):\n","    return sys.getsizeof(pickle.dumps(clf))\n","\n","\n","def classification_metrics_report(clf, x_train, y_train, x_test, y_test, display_scores=[],\n","           sample_weight=None, refit=False, importance_plot=False,\n","           confusion_labels=None, feature_labels=None, verbose=True):\n","    \"\"\" Trains the passed classifier if not already trained and reports\n","        various metrics of the trained classifier \"\"\"\n","    \n","    dump = dict()\n","    \n","    ## Train if not already trained\n","    clf, train_predictions, \\\n","    train_acc, train_time = train_clf(clf, x_train, y_train,\n","                                      sample_weight=sample_weight,\n","                                      refit=refit)\n","    ## Testing\n","    start = timeit.default_timer()\n","    test_predictions = clf.predict(x_test)\n","    end = timeit.default_timer()\n","    test_time = end - start\n","    \n","    test_acc = accuracy_score(y_test, test_predictions)\n","    y_probs = clf.predict_proba(x_test)[:, 1]\n","    \n","    roc_auc = roc_auc_score(y_test, y_probs)\n","    \n","    f2_score = fbeta_score(y_test, y_probs,beta=2)  \n","\n","    ## Additional scores\n","    scores_dict = dict()\n","    for func in display_scores:\n","        scores_dict[func.__name__] = [func(y_train, train_predictions),\n","                                      func(y_test, test_predictions)]\n","        \n","    ## Model Memory\n","    model_mem = round(model_memory_size(clf) / 1024, 2)\n","    \n","    print(clf)\n","    print(\"\\n=============================> TRAIN-TEST DETAILS <======================================\")\n","    \n","    ## Metrics\n","    print(f\"Train Size: {x_train.shape[0]} samples\")\n","    print(f\" Test Size: {x_test.shape[0]} samples\")\n","    print(\"---------------------------------------------\")\n","    print(f\"Training Time: {round(train_time, 3)} seconds\")\n","    print(f\" Testing Time: {round(test_time, 3)} seconds\")\n","    print(\"---------------------------------------------\")\n","    print(\"Train Accuracy: \", train_acc)\n","    print(\" Test Accuracy: \", test_acc)\n","    print(\"---------------------------------------------\")\n","    \n","    if display_scores:\n","        for k, v in scores_dict.items():\n","            score_name = ' '.join(map(lambda x: x.title(), k.split('_')))\n","            print(f'Train {score_name}: ', v[0])\n","            print(f' Test {score_name}: ', v[1])\n","            print()\n","        print(\"---------------------------------------------\")\n","    \n","    print(\" Area Under ROC (test): \", roc_auc)\n","    print(\"---------------------------------------------\")\n","    print(f\"Model Memory Size: {model_mem} kB\")\n","    print(\"---------------------------------------------\")\n","    print(\" f2 score (test): \", f2_score)\n","    print(\"---------------------------------------------\")\n","    # print(\" Area Under ROC - Precision Recall Courve (test): \", auc_precision_recall)\n","    # print(\"---------------------------------------------\")\n","    print(\"\\n=============================> CLASSIFICATION REPORT <===================================\")\n","    \n","    ## Classification Report\n","    clf_rep = classification_report(y_test, test_predictions, output_dict=True)\n","    \n","    print(classification_report(y_test, test_predictions,\n","                                target_names=confusion_labels))\n","    \n","    \n","    if verbose:\n","        print(\"\\n================================> CONFUSION MATRIX <=====================================\")\n","    \n","        ## Confusion Matrix HeatMap\n","        display(confusion_plot(confusion_matrix(y_test, test_predictions),\n","                               labels=confusion_labels))\n","        print(\"\\n=======================================> PLOTS <=========================================\")\n","\n","\n","        ## Variable importance plot\n","        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n","        roc_axes = axes[0, 0]\n","        pr_axes = axes[0, 1]\n","        importances = None\n","\n","        if importance_plot:\n","            if not feature_labels:\n","                raise RuntimeError(\"'feature_labels' argument not passed \"\n","                                   \"when 'importance_plot' is True\")\n","\n","            try:\n","                importances = pd.Series(clf.feature_importances_,\n","                                        index=feature_labels) \\\n","                                .sort_values(ascending=False)\n","            except AttributeError:\n","                try:\n","                    importances = pd.Series(clf.coef_.ravel(),\n","                                            index=feature_labels) \\\n","                                    .sort_values(ascending=False)\n","                except AttributeError:\n","                    pass\n","\n","            if importances is not None:\n","                # Modifying grid\n","                grid_spec = axes[0, 0].get_gridspec()\n","                for ax in axes[:, 0]:\n","                    ax.remove()   # remove first column axes\n","                large_axs = fig.add_subplot(grid_spec[0:, 0])\n","\n","                # Plot importance curve\n","                feature_importance_plot(importances=importances.values,\n","                                        feature_labels=importances.index,\n","                                        ax=large_axs)\n","                large_axs.axvline(x=0)\n","\n","                # Axis for ROC and PR curve\n","                roc_axes = axes[0, 1]\n","                pr_axes = axes[1, 1]\n","            else:\n","                # remove second row axes\n","                for ax in axes[1, :]:\n","                    ax.remove()\n","        else:\n","            # remove second row axes\n","            for ax in axes[1, :]:\n","                ax.remove()\n","\n","\n","        ## ROC and Precision-Recall curves\n","        clf_name = clf.__class__.__name__\n","        roc_plot(y_test, y_probs, clf_name, ax=roc_axes)\n","        precision_recall_plot(y_test, y_probs, clf_name, ax=pr_axes)\n","\n","        fig.subplots_adjust(wspace=5)\n","        fig.tight_layout()\n","        display(fig)\n","\n","        ## Precison vs Recall Curve \n","        p,r,threshold=plot_precision_recall_curve(y_test,y_probs)\n","        auc_precision_recall=auc(r,p)\n","        PrecisionRecallDisplay.from_estimate(clf,X_test,y_test)\n","\n","\n","        \n","    ## Dump to report_dict\n","    dump = dict(clf=clf, accuracy=[train_acc, test_acc], **scores_dict,\n","                train_time=train_time, train_predictions=train_predictions,\n","                test_time=test_time, test_predictions=test_predictions,\n","                test_probs=y_probs, report=clf_rep, roc_auc=roc_auc,\n","                model_memory=model_mem)\n","    \n","    return clf, dump\n","\n","\n","def compare_models(y_test=None, clf_reports=[], labels=[], score='accuracy'):\n","    \"\"\" Compare evaluation metrics for the True Positive class [1] of \n","        binary classifiers passed in the argument and plot ROC and PR curves.\n","        \n","        Arguments:\n","        ---------\n","        y_test: to plot ROC and Precision-Recall curves\n","         score: is the name corresponding to the sklearn metrics\n","        \n","        Returns:\n","        -------\n","        compare_table: pandas DataFrame containing evaluated metrics\n","                  fig: `matplotlib` figure object with ROC and PR curves \"\"\"\n","\n","    \n","    ## Classifier Labels\n","    default_names = [rep['clf'].__class__.__name__ for rep in clf_reports]\n","    clf_names =  labels if len(labels) == len(clf_reports) else default_names\n","    \n","    \n","    ## Compare Table\n","    table = dict()\n","    index = ['Train ' + score, 'Test ' + score, 'Overfitting', 'ROC Area',\n","             'Precision', 'Recall', 'F1-score', 'Support']\n","    for i in range(len(clf_reports)):\n","        scores = [round(i, 3) for i in clf_reports[i][score]]\n","        \n","        roc_auc = clf_reports[i]['roc_auc']\n","        \n","        # Get metrics of True Positive class from sklearn classification_report\n","        true_positive_metrics = list(clf_reports[i]['report'][\"1\"].values())\n","        \n","        table[clf_names[i]] = scores + [scores[1] < scores[0], roc_auc] + \\\n","                              true_positive_metrics\n","    \n","    table = pd.DataFrame(data=table, index=index)\n","    \n","    \n","    ## Compare Plots\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n","    \n","    # ROC and Precision-Recall\n","    for i in range(len(clf_reports)):\n","        clf_probs = clf_reports[i]['test_probs']\n","        roc_plot(y_test, clf_probs, label=clf_names[i],\n","                 compare=True, ax=axes[0])\n","        precision_recall_plot(y_test, clf_probs, label=clf_names[i],\n","                              compare=True, ax=axes[1])\n","    # Plot No-Info classifier\n","    axes[0].plot([0,1], [0,1], linestyle='--', color='green')\n","        \n","    fig.tight_layout()\n","    plt.close()\n","    \n","    return table.T, fig"],"metadata":{"id":"nv0RaQqooglj","executionInfo":{"status":"ok","timestamp":1677268491826,"user_tz":360,"elapsed":86,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/sample_data/mnist_train_small.csv')"],"metadata":{"id":"_-fd18i5oy_7","executionInfo":{"status":"ok","timestamp":1677265645022,"user_tz":360,"elapsed":1847,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["df.iloc[:,-1].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJ8Mu9Xy8dkv","executionInfo":{"status":"ok","timestamp":1677267790983,"user_tz":360,"elapsed":81,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}},"outputId":"3cecc82c-9f61-41eb-8cd5-f227c27b0524"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    19499\n","1      500\n","Name: 0.590, dtype: int64"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["##2. Data Preprocessing¶\n","x = df.iloc[:, 1:]\n","y = df.iloc[:,-1]\n","\n","categorical_columns = list(x.select_dtypes(include='category').columns)\n","numeric_columns = list(x.select_dtypes(exclude='category').columns)\n","\n","from sklearn.model_selection import train_test_split\n","\n","data_splits = train_test_split(x, y, test_size=0.25, random_state=0,\n","                               shuffle=True, stratify=y)\n","x_train, x_test, y_train, y_test = data_splits\n","\n","list(map(lambda x: x.shape, [x, y, x_train, x_test, y_train, y_test]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On5Jzhrh0hKU","executionInfo":{"status":"ok","timestamp":1677267838624,"user_tz":360,"elapsed":217,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}},"outputId":"92f52d09-1283-4093-832f-065e90ba74ac"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(19999, 784), (19999,), (14999, 784), (5000, 784), (14999,), (5000,)]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["#5 XGBoost with default parameters\n","from xgboost import XGBClassifier\n","from sklearn.utils import class_weight\n","from sklearn import metrics\n","\n","primary_eval_metric = metrics.f1_score\n","confusion_lbs = ['Not Survived', 'Survived']\n","\n","## Compute `class_weights` using sklearn\n","cls_weight = (y_train.shape[0] - np.sum(y_train)) / np.sum(y_train)\n","\n","xgb_clf_default = XGBClassifier(scale_pos_weight=cls_weight,\n","                                random_state=0, n_jobs=-1)\n","xgb_clf_default.fit(x_train, y_train);\n","\n","xgb_clf_default, xgb_report_default = classification_metrics_report(xgb_clf_default, x_train, y_train,\n","                                             x_test, y_test,\n","                                             display_scores=[primary_eval_metric],\n","                                             importance_plot=True,\n","                                             feature_labels=x_test.columns,\n","                                             confusion_labels=confusion_lbs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"79rDnslc1V3C","executionInfo":{"status":"error","timestamp":1677267851889,"user_tz":360,"elapsed":12332,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}},"outputId":"8e6660ad-f693-4b83-e18b-a08a9a5ea3df"},"execution_count":47,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-387f60a09360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mxgb_clf_default\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m xgb_clf_default, xgb_report_default = classification_metrics_report(xgb_clf_default, x_train, y_train,\n\u001b[0m\u001b[1;32m     17\u001b[0m                                              \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                              \u001b[0mdisplay_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprimary_eval_metric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-e274956f7f64>\u001b[0m in \u001b[0;36mclassification_metrics_report\u001b[0;34m(clf, x_train, y_train, x_test, y_test, display_scores, sample_weight, refit, importance_plot, confusion_labels, feature_labels, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mf2_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m## Additional scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \"\"\"\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qUONEwYW23Rc","executionInfo":{"status":"ok","timestamp":1677267900658,"user_tz":360,"elapsed":3,"user":{"displayName":"Divya Mereddy","userId":"11416629501838888552"}},"outputId":"fec32dc7-bed9-4a54-abee-87b9749460af"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method IndexOpsMixin.value_counts of 13821    0\n","17350    0\n","9049     0\n","3905     0\n","7014     0\n","        ..\n","15903    0\n","2432     0\n","9515     0\n","9989     0\n","7021     0\n","Name: 0.590, Length: 5000, dtype: int64>"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":[],"metadata":{"id":"B8JvnFZi9NqM"},"execution_count":null,"outputs":[]}]}